{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2ddb1f",
   "metadata": {},
   "source": [
    "<H2><center> Corporate Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a09142",
   "metadata": {},
   "source": [
    "<H4>Description:</H4> This notebook preprocesses company names by removing common terms (e.g., \"Ltd,\" \"Solutions,\" \"Technologies\" etc) and applying text normalization (lowercasing and lemmatization). It uses TF-IDF vectorization and cosine similarity to match a query name against a database, enabling identification even with variations (e.g., \"ANGLO-CARIBBEAN CO., LTD.\" matches \"angl carribean\"). The data sources include SEC EDGAR, Wikidata, the OFAC Sanctions Database, and recent news articles mentioning company names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3c35b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f0fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompanyMatcher:\n",
    "    def __init__(self, database):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.raw_database = database  \n",
    "        self.database = [self.preprocess_text(name) for name in database]  # Preprocessed database\n",
    "        \n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        if self.database:\n",
    "            self.vectors = self.vectorizer.fit_transform(self.database)\n",
    "        else:\n",
    "            self.vectors = None \n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z0-9\\s]', '', text)  \n",
    "        text = re.sub(r'\\s+', ' ', text).strip() \n",
    "        \n",
    "        stopwords = {\"corporation\", \"limited\", \"ltd\", \"solutions\", \"technologies\", \n",
    "                     \"consulting\", \"consultancy\", \"services\", \"systems\", \"group\", \n",
    "                     \"inc\", \"pvt\", \"plc\", \"co\"}\n",
    "        \n",
    "        words = text.split()\n",
    "        words = [self.lemmatizer.lemmatize(word) for word in words if word not in stopwords]  # Apply lemmatization\n",
    "        return \" \".join(words)\n",
    "\n",
    "    def get_top_cosine_matches(self, query, top_n=5):\n",
    "        if not self.database:  \n",
    "            return []\n",
    "\n",
    "        query_cleaned = self.preprocess_text(query)\n",
    "        query_vector = self.vectorizer.transform([query_cleaned])\n",
    "        similarity_scores = cosine_similarity(query_vector, self.vectors).flatten()\n",
    "\n",
    "        top_n = min(top_n, len(similarity_scores)) \n",
    "        top_indices = np.argsort(-similarity_scores)[:top_n]\n",
    "        top_matches = [(self.raw_database[i], similarity_scores[i]) for i in top_indices]\n",
    "\n",
    "        return top_matches\n",
    "\n",
    "    def apply_fuzzy_matching(self, query, candidates):\n",
    "        if not candidates:\n",
    "            return None, None\n",
    "\n",
    "        query_cleaned = self.preprocess_text(query)\n",
    "        best_match, best_score = max(\n",
    "            ((name, fuzz.ratio(query_cleaned, self.preprocess_text(name))) for name, _ in candidates),\n",
    "            key=lambda x: x[1]\n",
    "        )\n",
    "\n",
    "        return (best_match, best_score)\n",
    "\n",
    "    def find_best_match(self, query, top_n=5):\n",
    "        top_matches = self.get_top_cosine_matches(query, top_n)\n",
    "        best_match, best_score = self.apply_fuzzy_matching(query, top_matches)\n",
    "        \n",
    "        return best_match, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8daec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompanyScreening:\n",
    "    def __init__(self, ofac_list):\n",
    "        self.SEC_BASE_URL = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "        self.WIKIDATA_URL = \"https://query.wikidata.org/sparql\"\n",
    "        self.NEWS_API_KEY = os.getenv(\"News_APIKEY\")\n",
    "        self.OFAC_LIST_FILE = ofac_list\n",
    "        with open(self.OFAC_LIST_FILE, \"r\") as f:\n",
    "            self.ofac_companies = [line.strip() for line in f]\n",
    "        self.matcher = CompanyMatcher(self.ofac_companies)\n",
    "\n",
    "    def check_sec_edgar(self, company_name):\n",
    "        params = {\"action\": \"getcompany\", \"company\": company_name, \"output\": \"atom\"}\n",
    "        headers = {\"User-Agent\": \"XXX (xxx@yyy.com)\"}\n",
    "        response = requests.get(self.SEC_BASE_URL, params = params, headers = headers)\n",
    "        if response.status_code == 200 and \"No matching companies\" not in response.text:\n",
    "            soup = BeautifulSoup(response.text, \"xml\")\n",
    "            cik_tag = soup.find(\"cik\")\n",
    "            edgar_profile_url = None\n",
    "            recent_8k_filings = []\n",
    "            \n",
    "            if cik_tag:\n",
    "                cik = cik_tag.text.strip()\n",
    "\n",
    "            three_years_ago = datetime.now() - timedelta(days=3*365)\n",
    "            filings = soup.find_all(\"entry\")\n",
    "\n",
    "            for filing in filings:\n",
    "                title = filing.find(\"title\").text\n",
    "                date_str = filing.find(\"updated\").text[:10]\n",
    "                filing_date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "\n",
    "                if \"8-K\" in title and filing_date >= three_years_ago:\n",
    "                    recent_8k_filings.append(title)\n",
    "\n",
    "            return {\n",
    "                \"SEC Registered\": \"Yes\",\n",
    "                \"CIK\": cik if cik_tag else \"Not available\",\n",
    "                \"Recent 8-K Filings\": recent_8k_filings[:3] if recent_8k_filings else \"None\"\n",
    "            }\n",
    "        return {\n",
    "            \"SEC Registered\": \"No\"\n",
    "        }\n",
    "\n",
    "    def check_ofac_sanctions(self, company_name, threshold=85):\n",
    "        match, score = self.matcher.find_best_match(company_name)\n",
    "        return {\n",
    "            \"OFAC Sanctioned\": \"Yes\" if score >= threshold else \"No\",\n",
    "            \"Closest OFAC Database Match\": match if score >= threshold else \"None\",\n",
    "        }\n",
    "\n",
    "    def check_wikidata_scandals(self, company_name):\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT ?company ?companyLabel ?industry ?industryLabel ?scandal ?scandalLabel ?description WHERE {{\n",
    "          ?company rdfs:label \"{company_name}\"@en.\n",
    "          ?company wdt:P31 wd:Q4830453.  # Instance of (Business/Company)\n",
    "          OPTIONAL {{ ?company wdt:P452 ?industry. }}  # Industry type\n",
    "          OPTIONAL {{ ?company schema:description ?description. FILTER (LANG(?description) = \"en\") }}\n",
    "\n",
    "          # Looking for scandals\n",
    "          OPTIONAL {{ ?company wdt:P793 ?scandal. }}  # Significant events (may include fraud cases, controversies)\n",
    "          OPTIONAL {{ ?company wdt:P5053 ?scandal. }} # Cause of dissolution (bankruptcy, fraud)\n",
    "          OPTIONAL {{ ?company wdt:P2416 ?scandal. }} # Scandals (direct connection)\n",
    "\n",
    "          SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        response = requests.get(self.WIKIDATA_URL, params={\"query\": query, \"format\": \"json\"})\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            return {\"Error\": \"Failed to fetch data\"}\n",
    "\n",
    "        data = response.json().get(\"results\", {}).get(\"bindings\", [])\n",
    "\n",
    "        if not data:\n",
    "            return {\"Status\": \"Not Found in Wikidata\"}\n",
    "\n",
    "        result = data[0]  # Take the first matched entry\n",
    "        company_qid = result[\"company\"][\"value\"].split(\"/\")[-1]\n",
    "        \n",
    "        description = result.get(\"description\", {}).get(\"value\", \"No description available\")\n",
    "        if \"scandal\" in result:\n",
    "            scandal_name = result[\"scandalLabel\"][\"value\"]\n",
    "            scandal_qid = result[\"scandal\"][\"value\"].split(\"/\")[-1]\n",
    "            scandal_link = f\"https://www.wikidata.org/wiki/{scandal_qid}\"\n",
    "\n",
    "        return {\n",
    "            \"Wikidata_QID\": company_qid,\n",
    "            \"Description\": description,\n",
    "            \"Scandals\": (scandal_name, scandal_link) if \"scandal\" in result else \"No known scandals\",\n",
    "        }\n",
    "    def get_news(self, company_name):\n",
    "        url = f\"https://newsapi.org/v2/everything?q={company_name}&language=en&sortBy=publishedAt&apiKey={self.NEWS_API_KEY}\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            return {\"Recent News\": \"Error fetching news\"}\n",
    "\n",
    "        news_data = response.json()\n",
    "        articles = news_data.get(\"articles\", [])\n",
    "\n",
    "        filtered_articles = [article[\"title\"] for article in articles if company_name.lower() in article[\"title\"].lower()]\n",
    "        return {\"Recent News\": filtered_articles[:3] if filtered_articles else \"No relevant news found\"}\n",
    "\n",
    "    def screen_company(self, company_name):\n",
    "        result = {\"Company\": company_name}\n",
    "        result.update(self.check_sec_edgar(company_name))\n",
    "        result.update(self.check_ofac_sanctions(company_name))\n",
    "        result.update(self.check_wikidata_scandals(company_name))\n",
    "        result.update(self.get_news(company_name))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_screening = CompanyScreening(\"Data/ofac_list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd4af5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Company\": \"Theranos\",\n",
      "    \"SEC Registered\": \"Yes\",\n",
      "    \"CIK\": \"0001313697\",\n",
      "    \"Recent 8-K Filings\": \"None\",\n",
      "    \"OFAC Sanctioned\": \"No\",\n",
      "    \"Closest OFAC Database Match\": \"None\",\n",
      "    \"Status\": \"Not Found in Wikidata\",\n",
      "    \"Recent News\": [\n",
      "        \"Walgreens once ruled. Then came Amazon, Theranos \\u2014 and some costly bets\",\n",
      "        \"Convicted fraudster and former Theranos CEO Elizabeth Holmes is still guilty [Followup]\",\n",
      "        \"Federal court denies Theranos founder Elizabeth Holmes appeal to overturn fraud conviction\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "company = \"Theranos\"\n",
    "results = company_screening.screen_company(company)\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c2908d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Company\": \"angl carribean\",\n",
      "    \"SEC Registered\": \"Yes\",\n",
      "    \"CIK\": \"Not available\",\n",
      "    \"Recent 8-K Filings\": \"None\",\n",
      "    \"OFAC Sanctioned\": \"Yes\",\n",
      "    \"Closest OFAC Database Match\": \"ANGLO-CARIBBEAN CO., LTD.\",\n",
      "    \"Status\": \"Not Found in Wikidata\",\n",
      "    \"Recent News\": \"No relevant news found\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "company = \"angl carribean\"\n",
    "results = company_screening.screen_company(company)\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69dd3326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Company\": \"Wirecard\",\n",
      "    \"SEC Registered\": \"Yes\",\n",
      "    \"CIK\": \"0001586941\",\n",
      "    \"Recent 8-K Filings\": \"None\",\n",
      "    \"OFAC Sanctioned\": \"No\",\n",
      "    \"Closest OFAC Database Match\": \"None\",\n",
      "    \"Wikidata_QID\": \"Q587325\",\n",
      "    \"Description\": \"insolvent German financial services provider\",\n",
      "    \"Scandals\": [\n",
      "        \"Wirecard scandal\",\n",
      "        \"https://www.wikidata.org/wiki/Q96655771\"\n",
      "    ],\n",
      "    \"Recent News\": [\n",
      "        \"Bulgarians convicted in UK of being Russian spies working for Wirecard fugitive (Reuters)\",\n",
      "        \"The Wirecard fugitive, Russian intelligence and a Bulgarian spy ring\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "company = \"Wirecard\"\n",
    "results = company_screening.screen_company(company)\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a30e2666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Company\": \"Lehman Brothers\",\n",
      "    \"SEC Registered\": \"Yes\",\n",
      "    \"CIK\": \"0001437948\",\n",
      "    \"Recent 8-K Filings\": \"None\",\n",
      "    \"OFAC Sanctioned\": \"No\",\n",
      "    \"Closest OFAC Database Match\": \"None\",\n",
      "    \"Wikidata_QID\": \"Q212900\",\n",
      "    \"Description\": \"defunct American financial services firm\",\n",
      "    \"Scandals\": [\n",
      "        \"bankruptcy of Lehman Brothers\",\n",
      "        \"https://www.wikidata.org/wiki/Q3269580\"\n",
      "    ],\n",
      "    \"Recent News\": [\n",
      "        \"FTX\\u2019s US$950 million bankruptcy fees among costliest since Lehman Brothers\",\n",
      "        \"FTX\\u2019s US$950 million bankruptcy fees among costliest since Lehman Brothers\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "company = \"Lehman Brothers\"\n",
    "results = company_screening.screen_company(company)\n",
    "print(json.dumps(results, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
